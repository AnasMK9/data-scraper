{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Database URL from environment\n",
    "DATABASE_URL = os.getenv('DATABASE_URL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def connect_db():\n",
    "    return psycopg2.connect(DATABASE_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_glassdoor():\n",
    "    url = \"https://www.glassdoor.com/Job/jobs.htm\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    jobs = soup.find_all(\"li\", class_=\"jl\")  # Replace with the actual HTML structure\n",
    "\n",
    "    job_listings = []\n",
    "    for job in jobs:\n",
    "        job_title = job.find(\"div\", class_=\"jobTitle\").text.strip()\n",
    "        company_name = job.find(\"div\", class_=\"jobEmpolyerName\").text.strip()\n",
    "        location = job.find(\"span\", class_=\"subtle loc\").text.strip()\n",
    "        date_posted = job.find(\"span\", class_=\"date\").text.strip()\n",
    "        job_description = job.find(\"div\", class_=\"job-snippet\").text.strip()\n",
    "        salary_range = job.find(\"span\", class_=\"salaryText\").text.strip() if job.find(\"span\", class_=\"salaryText\") else \"N/A\"\n",
    "        url = \"https://www.glassdoor.com\" + job.find(\"a\", class_=\"jobLink\")[\"href\"]\n",
    "\n",
    "        job_listings.append({\n",
    "            \"job_title\": job_title,\n",
    "            \"company_name\": company_name,\n",
    "            \"location\": location,\n",
    "            \"date_posted\": datetime.strptime(date_posted, \"%m/%d/%Y\").date(),  # Example date format\n",
    "            \"job_description\": job_description,\n",
    "            \"salary_range\": salary_range,\n",
    "            \"url\": url\n",
    "        })\n",
    "\n",
    "    return job_listings\n",
    "\n",
    "# Scrape jobs and display the result\n",
    "job_listings = scrape_glassdoor()\n",
    "job_listings[:3]  # Show first 3 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"postgres\" (92.242.129.221), port 5432 failed: Operation timed out\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m         cursor\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Insert scraped jobs into the database\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[43mconnect_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m job_listings:\n\u001b[1;32m     26\u001b[0m     insert_job_listing(connection, job)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mconnect_db\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect_db\u001b[39m():\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATABASE_URL\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/web-scraper/webscraper/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[0;31mOperationalError\u001b[0m: connection to server at \"postgres\" (92.242.129.221), port 5432 failed: Operation timed out\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "source": [
    "def insert_job_listing(connection, job_data):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO job_listings (job_title, company_name, location, date_posted, job_description, salary_range, url)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (job_title, company_name, location, date_posted) DO NOTHING;\n",
    "        \"\"\", (\n",
    "            job_data['job_title'],\n",
    "            job_data['company_name'],\n",
    "            job_data['location'],\n",
    "            job_data['date_posted'],\n",
    "            job_data['job_description'],\n",
    "            job_data['salary_range'],\n",
    "            job_data['url']\n",
    "        ))\n",
    "        connection.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "# Insert scraped jobs into the database\n",
    "connection = connect_db()\n",
    "for job in job_listings:\n",
    "    insert_job_listing(connection, job)\n",
    "connection.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
